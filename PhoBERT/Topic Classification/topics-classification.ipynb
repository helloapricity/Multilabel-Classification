{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6851024,"sourceType":"datasetVersion","datasetId":3938008}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the vncorenlp python wrapper\n!pip install vncorenlp","metadata":{"execution":{"iopub.status.busy":"2023-11-24T06:56:16.080536Z","iopub.execute_input":"2023-11-24T06:56:16.080853Z","iopub.status.idle":"2023-11-24T06:56:31.653841Z","shell.execute_reply.started":"2023-11-24T06:56:16.080824Z","shell.execute_reply":"2023-11-24T06:56:31.652592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter) \n!mkdir -p vncorenlp/models/wordsegmenter\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n!mv vi-vocab vncorenlp/models/wordsegmenter/\n!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/","metadata":{"execution":{"iopub.status.busy":"2023-11-24T06:56:31.656054Z","iopub.execute_input":"2023-11-24T06:56:31.656396Z","iopub.status.idle":"2023-11-24T06:56:41.360159Z","shell.execute_reply.started":"2023-11-24T06:56:31.656366Z","shell.execute_reply":"2023-11-24T06:56:41.358932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nfrom vncorenlp import VnCoreNLP\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom ast import literal_eval","metadata":{"execution":{"iopub.status.busy":"2023-11-24T06:56:41.361774Z","iopub.execute_input":"2023-11-24T06:56:41.362173Z","iopub.status.idle":"2023-11-24T06:56:42.190800Z","shell.execute_reply.started":"2023-11-24T06:56:41.362135Z","shell.execute_reply":"2023-11-24T06:56:42.189785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:03:29.187968Z","iopub.execute_input":"2023-11-24T07:03:29.188287Z","iopub.status.idle":"2023-11-24T07:03:41.029945Z","shell.execute_reply.started":"2023-11-24T07:03:29.188261Z","shell.execute_reply":"2023-11-24T07:03:41.028680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:03:41.031545Z","iopub.execute_input":"2023-11-24T07:03:41.031872Z","iopub.status.idle":"2023-11-24T07:03:52.736515Z","shell.execute_reply.started":"2023-11-24T07:03:41.031843Z","shell.execute_reply":"2023-11-24T07:03:52.735407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:03:52.737966Z","iopub.execute_input":"2023-11-24T07:03:52.738308Z","iopub.status.idle":"2023-11-24T07:04:04.827157Z","shell.execute_reply.started":"2023-11-24T07:03:52.738280Z","shell.execute_reply":"2023-11-24T07:04:04.826002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\nfrom datasets import Dataset, load_metric, load_dataset\nimport matplotlib.pyplot as plt\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:04.829052Z","iopub.execute_input":"2023-11-24T07:04:04.829474Z","iopub.status.idle":"2023-11-24T07:04:15.191417Z","shell.execute_reply.started":"2023-11-24T07:04:04.829435Z","shell.execute_reply":"2023-11-24T07:04:15.190450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topics_path = \"/kaggle/input/datalawvn/topics_datalaw.json\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segmented_datalaw_topics = pd.read_json(topics_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into train and remaining (80% - 20%)\ntrain_topics_dataset = segmented_datalaw_topics.sample(frac=0.8, random_state=42)\nremaining_dataset = segmented_datalaw_topics.drop(train_topics_dataset.index)\n\n# Split the remaining dataset into validation and test (50% - 50%)\nvalidation_topics_dataset = remaining_dataset.sample(frac=0.5, random_state=42)\ntest_topics_dataset = remaining_dataset.drop(validation_topics_dataset.index)\n\n# Print the number of records in each set\nprint(f'The training topics dataset has {len(train_topics_dataset)} records.')\nprint(f'The validation topics dataset has {len(validation_topics_dataset)} records.')\nprint(f'The test topics dataset has {len(test_topics_dataset)} records.')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:15.192771Z","iopub.execute_input":"2023-11-24T07:04:15.193871Z","iopub.status.idle":"2023-11-24T07:04:17.066274Z","shell.execute_reply.started":"2023-11-24T07:04:15.193832Z","shell.execute_reply":"2023-11-24T07:04:17.065039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [label for label in train_topics_dataset.columns if label != 'question']\nid2label = {idx: label for idx, label in enumerate(labels)}\nlabel2id = {label: idx for idx, label in enumerate(labels)}\nlabels[:5]","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:17.067437Z","iopub.execute_input":"2023-11-24T07:04:17.067747Z","iopub.status.idle":"2023-11-24T07:04:17.081864Z","shell.execute_reply.started":"2023-11-24T07:04:17.067721Z","shell.execute_reply":"2023-11-24T07:04:17.080795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hg_train_topics_dataset = Dataset.from_pandas(train_topics_dataset)\nhg_test_topics_dataset = Dataset.from_pandas(test_topics_dataset)\nhg_validation_topics_dataset = Dataset.from_pandas(validation_topics_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:17.083662Z","iopub.execute_input":"2023-11-24T07:04:17.084082Z","iopub.status.idle":"2023-11-24T07:04:22.175935Z","shell.execute_reply.started":"2023-11-24T07:04:17.084042Z","shell.execute_reply":"2023-11-24T07:04:22.175010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The length of hg_train_topics_dataset is {len(hg_train_topics_dataset)}.\\n')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:22.177459Z","iopub.execute_input":"2023-11-24T07:04:22.177839Z","iopub.status.idle":"2023-11-24T07:04:22.182753Z","shell.execute_reply.started":"2023-11-24T07:04:22.177801Z","shell.execute_reply":"2023-11-24T07:04:22.181790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:22.184137Z","iopub.execute_input":"2023-11-24T07:04:22.184513Z","iopub.status.idle":"2023-11-24T07:04:23.538122Z","shell.execute_reply.started":"2023-11-24T07:04:22.184479Z","shell.execute_reply":"2023-11-24T07:04:23.537229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The unknown token is {tokenizer.unk_token} and the ID for the unknown token is {tokenizer.unk_token_id}')\nprint(f'The seperator token is {tokenizer.sep_token} and the ID for the seperator token is {tokenizer.sep_token_id}')\nprint(f'The pad token is {tokenizer.pad_token} and the ID for the pad token is {tokenizer.pad_token_id}')\nprint(f'The sentence level classification token is {tokenizer.cls_token} and the ID for the classification token is {tokenizer.cls_token_id}')\nprint(f'The mask token is {tokenizer.mask_token} and the ID for the mask token is {tokenizer.mask_token_id}')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:23.539272Z","iopub.execute_input":"2023-11-24T07:04:23.539537Z","iopub.status.idle":"2023-11-24T07:04:23.545474Z","shell.execute_reply.started":"2023-11-24T07:04:23.539513Z","shell.execute_reply":"2023-11-24T07:04:23.544458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_topics_dataset(examples):\n  # take a batch of texts\n  text = examples[\"question\"]\n  # encode them\n  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256)\n  # add labels\n  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n  # create numpy array of shape (batch_size, num_labels)\n  labels_matrix = np.zeros((len(text), len(labels)))\n  # fill numpy array\n  for idx, label in enumerate(labels):\n    labels_matrix[:, idx] = labels_batch[label]\n\n  encoding[\"labels\"] = labels_matrix.tolist()\n  \n  return encoding","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:23.546785Z","iopub.execute_input":"2023-11-24T07:04:23.547154Z","iopub.status.idle":"2023-11-24T07:04:23.556774Z","shell.execute_reply.started":"2023-11-24T07:04:23.547118Z","shell.execute_reply":"2023-11-24T07:04:23.555820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset_topics_train = hg_train_topics_dataset.map(tokenize_topics_dataset, batched=True, remove_columns=hg_train_topics_dataset.column_names)\nencoded_dataset_topics_test = hg_test_topics_dataset.map(tokenize_topics_dataset, batched=True, remove_columns=hg_train_topics_dataset.column_names)\nencoded_dataset_topics_validation = hg_validation_topics_dataset.map(tokenize_topics_dataset, batched=True, remove_columns=hg_train_topics_dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:04:23.557976Z","iopub.execute_input":"2023-11-24T07:04:23.558312Z","iopub.status.idle":"2023-11-24T07:12:23.878678Z","shell.execute_reply.started":"2023-11-24T07:04:23.558285Z","shell.execute_reply":"2023-11-24T07:12:23.877664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset_topics_train.set_format(\"torch\")\nencoded_dataset_topics_test.set_format(\"torch\")\nencoded_dataset_topics_validation.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:12:23.879962Z","iopub.execute_input":"2023-11-24T07:12:23.880324Z","iopub.status.idle":"2023-11-24T07:12:23.886639Z","shell.execute_reply.started":"2023-11-24T07:12:23.880294Z","shell.execute_reply":"2023-11-24T07:12:23.885593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T06:59:49.253261Z","iopub.execute_input":"2023-11-10T06:59:49.253583Z","iopub.status.idle":"2023-11-10T06:59:49.263883Z","shell.execute_reply.started":"2023-11-10T06:59:49.253552Z","shell.execute_reply":"2023-11-10T06:59:49.263076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base-v2\", num_labels=len(labels), id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T06:59:49.264960Z","iopub.execute_input":"2023-11-10T06:59:49.265305Z","iopub.status.idle":"2023-11-10T06:59:53.633129Z","shell.execute_reply.started":"2023-11-10T06:59:49.265261Z","shell.execute_reply":"2023-11-10T06:59:53.632381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric_name = \"f1\"","metadata":{"execution":{"iopub.status.busy":"2023-11-10T06:59:53.634156Z","iopub.execute_input":"2023-11-10T06:59:53.634442Z","iopub.status.idle":"2023-11-10T06:59:53.638410Z","shell.execute_reply.started":"2023-11-10T06:59:53.634418Z","shell.execute_reply":"2023-11-10T06:59:53.637402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.get(\"labels\")\n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get('logits')\n        # compute custom loss\n        # Class weighting\n        loss_fct = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:10:01.401810Z","iopub.execute_input":"2023-11-10T07:10:01.402791Z","iopub.status.idle":"2023-11-10T07:10:01.410929Z","shell.execute_reply.started":"2023-11-10T07:10:01.402739Z","shell.execute_reply":"2023-11-10T07:10:01.409915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelsss = np.array(labels)\nprint(f\"Labels shape: {labelsss.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:11:49.350469Z","iopub.execute_input":"2023-11-10T07:11:49.351273Z","iopub.status.idle":"2023-11-10T07:11:49.362400Z","shell.execute_reply.started":"2023-11-10T07:11:49.351237Z","shell.execute_reply":"2023-11-10T07:11:49.361271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./topics_classification\",\n    logging_dir=\"./topics_classification/logs\",\n    evaluation_strategy='epoch',\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    gradient_accumulation_steps=4,\n    eval_accumulation_steps = 2,\n    eval_delay=0.5,\n    learning_rate=3e-5,\n    weight_decay=1e-4,\n    max_grad_norm=1.0,\n    num_train_epochs=10,\n    lr_scheduler_type=\"reduce_lr_on_plateau\", # Giảm khi hiệu suất không cải thiện trên tập validation.\n    warmup_ratio=0.1,\n    adam_beta1=0.9,\n    adam_beta2=0.999,\n    adam_epsilon=1e-08,\n    log_level='debug',\n    logging_strategy='epoch',\n    save_strategy='epoch',\n    save_total_limit=5,\n    save_safetensors=True,\n    seed=42,\n    fp16=False,\n    dataloader_num_workers=num_cpus,\n    run_name=\"PhoBERTv2_topics\",\n    load_best_model_at_end=True,\n    metric_for_best_model=metric_name\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:03:14.487515Z","iopub.execute_input":"2023-11-10T07:03:14.488285Z","iopub.status.idle":"2023-11-10T07:03:14.497433Z","shell.execute_reply.started":"2023-11-10T07:03:14.488251Z","shell.execute_reply":"2023-11-10T07:03:14.496446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\nfrom transformers import EvalPrediction\nimport torch\n\ndef multi_label_metrics(predictions, labels, threshold=0.5):\n    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(torch.Tensor(predictions))\n    # next, use threshold to turn them into integer predictions\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    y_true = labels\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n    precision_micro_average = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n    recall_micro_average = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n    roc_auc = roc_auc_score(y_true, y_pred, average='micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    # return as dictionary\n    metrics = {\n        'f1': f1_micro_average,\n        'precision': precision_micro_average,\n        'recall': recall_micro_average,\n        'roc_auc': roc_auc,\n        'accuracy': accuracy\n    }\n    return metrics\n\ndef compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n    result = multi_label_metrics(\n        predictions=preds, \n        labels=p.label_ids)\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:03:14.917075Z","iopub.execute_input":"2023-11-10T07:03:14.917410Z","iopub.status.idle":"2023-11-10T07:03:14.930479Z","shell.execute_reply.started":"2023-11-10T07:03:14.917386Z","shell.execute_reply":"2023-11-10T07:03:14.928505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:15:47.502154Z","iopub.execute_input":"2023-11-10T07:15:47.502824Z","iopub.status.idle":"2023-11-10T07:15:47.550430Z","shell.execute_reply.started":"2023-11-10T07:15:47.502783Z","shell.execute_reply":"2023-11-10T07:15:47.548967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset_topics_train,\n    eval_dataset=encoded_dataset_topics_validation,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)])\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:16:28.668659Z","iopub.execute_input":"2023-11-10T07:16:28.669602Z","iopub.status.idle":"2023-11-10T07:48:14.918354Z","shell.execute_reply.started":"2023-11-10T07:16:28.669550Z","shell.execute_reply":"2023-11-10T07:48:14.917305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:02:00.855237Z","iopub.status.idle":"2023-11-10T07:02:00.855674Z","shell.execute_reply.started":"2023-11-10T07:02:00.855497Z","shell.execute_reply":"2023-11-10T07:02:00.855514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = hg_test_topics_dataset[\"question\"][1000]\n\nencoding = tokenizer(text, return_tensors=\"pt\")\nencoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n\noutputs = trainer.model(**encoding)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:02:00.857373Z","iopub.status.idle":"2023-11-10T07:02:00.857743Z","shell.execute_reply.started":"2023-11-10T07:02:00.857571Z","shell.execute_reply":"2023-11-10T07:02:00.857587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = outputs.logits\nlogits.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:02:00.858803Z","iopub.status.idle":"2023-11-10T07:02:00.859136Z","shell.execute_reply.started":"2023-11-10T07:02:00.858974Z","shell.execute_reply":"2023-11-10T07:02:00.858989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply sigmoid + threshold\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(logits.squeeze().cpu())\npredictions = np.zeros(probs.shape)\npredictions[np.where(probs >= 0.5)] = 1\n# turn predicted id's into actual label names\npredicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\nprint(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T07:02:00.860112Z","iopub.status.idle":"2023-11-10T07:02:00.860440Z","shell.execute_reply.started":"2023-11-10T07:02:00.860278Z","shell.execute_reply":"2023-11-10T07:02:00.860294Z"},"trusted":true},"execution_count":null,"outputs":[]}]}